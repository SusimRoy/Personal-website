<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | Susim Mukul Roy</title><link>https://SusimRoy.github.io/Personal-wesbite/project/</link><atom:link href="https://SusimRoy.github.io/Personal-wesbite/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 25 Nov 2023 00:00:00 +0000</lastBuildDate><image><url>https://SusimRoy.github.io/Personal-wesbite/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Projects</title><link>https://SusimRoy.github.io/Personal-wesbite/project/</link></image><item><title>A Sequential Memory Preserving Approach for Few-Shot Image Classification</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project20/</link><pubDate>Sat, 25 Nov 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project20/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>we model the meta-training set as the combination of all the individual task specific training sets instead of a multi-task setting.&lt;/li>
&lt;li>We understand the cross-domain connection stored in the feature extractor using our Memory Augmented Propagation network which stores the information from the previous layers of our backbone.&lt;/li>
&lt;li>We apply self-attention on each output feature map of the layers of our backbone in a hierarchical manner to find co-dependency.&lt;/li>
&lt;li>We test on the popular CIFAR-FS and miniImageNet datasets and find that our results are at par and sometimes even better than convolutional based SOTA approaches like MetaOptNet.&lt;/li>
&lt;/ul></description></item><item><title>On Discriminating Intentional Adversarial Perturbations with Unintentional Noises</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project19/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project19/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>We propose a class-independent detection method, CIAI, using Maximum Mean Discrepancy and classifying the intended and unintended noise separately.&lt;/li>
&lt;li>We show how both types of noises affect the classification accuracy for gender prediction on the CelebA dataset. We show the detection accuracy which is comparable and at times exceeds the previous state-of-the-art detection methods including performance on unseen attacks.&lt;/li>
&lt;li>Using attention maps we further show features that help with the prediction of gender and detection of noises.&lt;/li>
&lt;/ul></description></item><item><title>Robustness of BNNs against White Box Attacks</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project17/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project17/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>An experimental work where we tested whether BNN posteriors are more robust to gradient based adversarial attacks when compared to the general learning based neural networks in SOTA architectures.&lt;/li>
&lt;li>Implemented BNN posterior in Alexnet,LeNet, Resnet34 and a custom made CNN to test the validity of the theoretical result. Each of these 4 models were attacked with FGSM and PGD variants.&lt;/li>
&lt;li>Implemented two bayesian estimation methods namely the conventional variational inference and one of it&amp;rsquo;s modified version called local reparametrisation trick into the three above models.&lt;/li>
&lt;li>Results indicate that Resnet34 takes a much longer time to train and has relatively poorer classification accuracy as compared to the other three models. A hypothesis supporting this fact is that Resnet34 has a more complex structure which doesn&amp;rsquo;t model the data distribution properly through the priors at each block.&lt;/li>
&lt;/ul></description></item><item><title>Training with Continuous Sensor System Parameters and Irregular Data</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project1/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project1/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Modelling of noise for CT simulations(e.g. Poisson-noise)by considering spatially non-uniform intensity distributions and in limited dosage environments(ULDCT).&lt;/li>
&lt;li>Create a pattern so that the intensity distribution becomes learnable.&lt;/li>
&lt;li>Apply an appropriate reconstruction technique which takes care of artifacts or likely noise patterns and generates back the original image which has high metric values when compared with ssim etc.&lt;/li>
&lt;/ul></description></item><item><title>Visual Motion Analysis from Images and Videos</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project16/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project16/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>The main objective was to work towards developing a software to find the optimal time to spray fungicides to prevent the spread of FHB disease among the common vegetation.&lt;/li>
&lt;li>Wheat and Canola flower data collection and annotation using SCVAT and storing them as PASCAL-VOC or YOLO format.&lt;/li>
&lt;li>Improving Yolov8 and Efficient-Det(pytorch version) algorithms to work on the created dataset by tuning hyperparameters in the former case and incorporating an attention module(e.g. CBAM) in the latter case.&lt;/li>
&lt;li>Deployment of the trained models on the &lt;a href="https://demo.sga.ai/" target="_blank" rel="noopener">demo Website&lt;/a> for usage by farmers and similar people for FHB prevention.&lt;/li>
&lt;/ul></description></item><item><title>Vulnerability of Diffusion Models to Adversarial Attacks</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project18/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project18/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Conducted an extensive literature survey of diffusion models and their advantages and disadvantages.&lt;/li>
&lt;li>Implemented an architecture which works with different pretrained DDPMs and classifiers.&lt;/li>
&lt;li>Developed a novel adversarial attack using the Class-Activation Maps of classifiers and the predicted noise maps from the UNet model of a DDPM which gives a better attack in terms of ASR, Robust accuracy and FID.&lt;/li>
&lt;li>Worked with datasets like CIFAR10, CelebaHQ, FFHQ etc.&lt;/li>
&lt;/ul></description></item><item><title>Deep Video Summarization</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project9/</link><pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project9/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Given an input video data, we find the most informative slides and summarize the content in the video in the form of natural language.&lt;/li>
&lt;li>We first encode the images using the CLIP model and then pass it through a U-Net inspired transformer encoder-decoder architecture with skip connections in order to score each frame.&lt;/li>
&lt;li>Finally, the frame-level scores to shot-level scores and finally use dynamic programming (0/1 knapsack) to decide which shots to pick as keyshots.&lt;/li>
&lt;/ul></description></item><item><title>Deep Q Learning</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project8/</link><pubDate>Tue, 25 Apr 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project8/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>The objective was to train a RL agent to play the world&amp;rsquo;s hardest game which is essentially to reach a goal point among arbitratrily moving obstacles.&lt;/li>
&lt;li>Created a simple MLP which projects from a n-dimensional state space to a m-dimensional action state which the RL agent should take.&lt;/li>
&lt;li>Created a custom reward function which penalizes the agent for being idle or getting stuck by an obstacle and rewards it for reaching the goal.&lt;/li>
&lt;/ul></description></item><item><title>Federated Learning</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project10/</link><pubDate>Thu, 20 Apr 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project10/</guid><description>&lt;h2>Summary&lt;/h2>
- Implemented the FedAvg algorithm from scratch on three popular datasets, namely MNIST, Coloured-MNIST and SVHN. &lt;br/>
- Compared them with the case when they were trained and tested in a non-federated manner. &lt;br/></description></item><item><title>Feedback Approach to Foster Motion Information in FPAR</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project6/</link><pubDate>Sun, 02 Apr 2023 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project6/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Improved the existing SparNet architecture by encorporating a feedback mechanism which basically embeds the finer information from the later layers of Resnet in it&amp;rsquo;s earlier layers.&lt;/li>
&lt;li>The Motion Prediction Block used the knowledge from the Action Recognition Block to incorporate it back into that in it&amp;rsquo;s first layer while taking care of the dimensions.&lt;/li>
&lt;li>Deployed the model on a webpage using flask framework where an user can input a video or an image and gets returned a heat map indicating the location of the action.&lt;/li>
&lt;/ul></description></item><item><title>Multimodal Art Database</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project11/</link><pubDate>Sun, 30 Oct 2022 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project11/</guid><description>&lt;h2>Summary&lt;/h2>
- A user had to input an artistic image and our software would detect the top k artists who could have possibly made the painting and store them in a local MariaDB database. &lt;br/>
- To find the similarity between input painting and the database, we used the CLIP model to first finetune on our art database and then using the cosine similarity between the stored embeddings and our input feature embedding. &lt;br/>
- The most likely images got stored in a normalized SQL tables with foreign keys linking between the image id table and the artist id table.</description></item><item><title>Detecting Adversarial Perturbations While Determining Intentional and Unintentional Noises</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project2/</link><pubDate>Tue, 30 Aug 2022 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project2/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>We proposed a class-independent detection method, CIAI, using Maximum Mean Discrepancy which classifies the intended(adversarial attacks) and unintended(for e.g. Gaussian) noise separately.&lt;/li>
&lt;li>The algorithm is multistage indicating that in the first stage, we use an MMD-based loss to train a Vision
Transformer initialized with trained classifier weights and in the second stage we use the trained detector for classification by freezing all the layers and adding three trainable layers for training.&lt;/li>
&lt;li>We show the detection accuracy which is comparable and at times exceeds the previous state-of-the-art detection methods, including performance on unseen attacks.&lt;/li>
&lt;/ul></description></item><item><title>UAV Guided UGV Movement</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project12/</link><pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project12/</guid><description>&lt;h2>Summary&lt;/h2>
- An autonomous drone had to navigate in hilly environment and store it's path while moving towards the goal point following which a UGV would follow the path made by the UAV and reach the endpoint. &lt;br/>
- Used OpenCV and segmentation techniques along with ROS to segment out road from surroundings using depth images.&lt;br/>
- Analyzed the drone movement using Gazebo and RVIZ in order to accurately find an optimal path for the UGV. &lt;br/>
- Sent messages to the UGV using ROSBags for it's movement post UAV arrival at goal.</description></item><item><title>International Micromouse Challenge</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project13/</link><pubDate>Tue, 30 Nov 2021 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project13/</guid><description>&lt;h2>Summary&lt;/h2>
- The objective was to make the micromouse autnomously reach a goal point after navigating through a maze. &lt;br/>
- Implemented the wall-following algorithm so that the micromouse keeps following a single wall using ROS. &lt;br/></description></item><item><title>Playlist Converter</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project5/</link><pubDate>Fri, 20 Aug 2021 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project5/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Created a website with VueJS and tailwindcss where an user can input an Apple playlist and a Spotify playlist will be created in their account which can be private/public as per their choice.&lt;/li>
&lt;li>Used an Apple token to get songs from the user&amp;rsquo;s playlist and thereby sent GET requests to Spotify to fetch the songs and finally sending a POST request to make the playlist.&lt;/li>
&lt;li>The algorithm we used to get the songs from Spotify is to add the first song which appears on searching with the corresponding name in the Apple playlist.&lt;/li>
&lt;/ul></description></item><item><title>Face Recognition using Clustering Algorithms.</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project15/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project15/</guid><description>&lt;h2>Summary&lt;/h2>
- Deploy a web model where an user can input an image and gets returned the most similar looking images to his face from a database. &lt;br/>
- Using clustering algorithms such as Resnet with PCA for feature dimensionality reduction, find the most similar faces with respect to the user.</description></item><item><title>Real Time Face Mask Detection</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project3/</link><pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project3/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Used VGG-19 to train on a publicly available kaggle dataset on masked/non-masked faces and obtained an accuracy of 99.8%.&lt;/li>
&lt;li>Used the haarCascades to detect the face in a real-time video and then apply our model to check whether the user has worn a mask or not.&lt;/li>
&lt;/ul></description></item><item><title>Autonomous Drone Obstacle Avoidance</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project14/</link><pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project14/</guid><description>&lt;h2>Summary&lt;/h2>
- An autonomous drone had to navigate in varying environment, starting from taking off and then detecting an Aruco Marker and landing on it. &lt;br/>
- Worked on detection of aruco marker and it's take-off and landing using ardupilot. &lt;br/>
- Worked on converting pointcloud data to laserscan for swift movement of the drone.</description></item><item><title>Pokemon Dashboard</title><link>https://SusimRoy.github.io/Personal-wesbite/project/project7/</link><pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate><guid>https://SusimRoy.github.io/Personal-wesbite/project/project7/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>A single webpage which shows different features of different pokemons and compares them with each other through multiple visualizations using interactive and informative graphics.&lt;/li>
&lt;li>Used interactive graphics like bubble plot along with radar plots and parallel graph plots to show distinctions between pokemons.&lt;/li>
&lt;/ul></description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Research_Project | Susim Mukul Roy</title><link>http://susimroy.github.io/tag/research_project/</link><atom:link href="http://susimroy.github.io/tag/research_project/index.xml" rel="self" type="application/rss+xml"/><description>Research_Project</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 01 Aug 2023 00:00:00 +0000</lastBuildDate><image><url>http://susimroy.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Research_Project</title><link>http://susimroy.github.io/tag/research_project/</link></image><item><title>Intensity Optimized CT Reconstruction</title><link>http://susimroy.github.io/project/project1/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>http://susimroy.github.io/project/project1/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Modelling of noise for CT simulations(e.g. Poisson-noise)by considering spatially non-uniform intensity distributions and in limited dosage environments(ULDCT).&lt;/li>
&lt;li>Create a pattern so that the intensity distribution becomes learnable.&lt;/li>
&lt;li>Apply an appropriate reconstruction technique which takes care of artifacts or likely noise patterns and generates back the original image which has high metric values when compared with ssim etc.&lt;/li>
&lt;/ul></description></item><item><title>Detecting Adversarial Perturbations While Determining Intentional and Unintentional Noises</title><link>http://susimroy.github.io/project/project2/</link><pubDate>Tue, 30 Aug 2022 00:00:00 +0000</pubDate><guid>http://susimroy.github.io/project/project2/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>We proposed a class-independent detection method, CIAI, using Maximum Mean Discrepancy which classifies the intended(adversarial attacks) and unintended(for e.g. Gaussian) noise separately.&lt;/li>
&lt;li>The algorithm is multistage indicating that in the first stage, we use an MMD-based loss to train a Vision
Transformer initialized with trained classifier weights and in the second stage we use the trained detector for classification by freezing all the layers and adding three trainable layers for training.&lt;/li>
&lt;li>We show the detection accuracy which is comparable and at times exceeds the previous state-of-the-art detection methods, including performance on unseen attacks.&lt;/li>
&lt;/ul></description></item><item><title>Referring Moving Object Segmentation</title><link>http://susimroy.github.io/project/project4/</link><pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate><guid>http://susimroy.github.io/project/project4/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Conducted an extensive literature survey to understand the working of the SOTA models like Referformer, MTTR etc.&lt;/li>
&lt;li>Improved RefVos by including the temporal information from the frames by taking their difference and sending it as input along with the 2nd frame among every 3 consecutive frame.&lt;/li>
&lt;li>To capture the new variety of features, made a new convolutional decoder to interpret the spatial and temporal information into accurately segmenting the object.&lt;/li>
&lt;li>Researched into joining the language and visual features using modules introduced by different papers such as a Multi-Scale Cross-Modal Feature Mining technique among others.&lt;/li>
&lt;li>Extended the training and testing dataset to JHMDB and DAVIS-17 along with the standard A2D dataset.&lt;/li>
&lt;/ul></description></item><item><title>Real Time Face Mask Detection</title><link>http://susimroy.github.io/project/project3/</link><pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate><guid>http://susimroy.github.io/project/project3/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Used VGG-19 to train on a publicly available kaggle dataset on masked/non-masked faces and obtained an accuracy of 99.8%.&lt;/li>
&lt;li>Used the haarCascades to detect the face in a real-time video and then apply our model to check whether the user has worn a mask or not.&lt;/li>
&lt;/ul></description></item></channel></rss>